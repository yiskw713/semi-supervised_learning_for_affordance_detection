{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import save_image\n",
    "from torchvision import transforms\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import scipy.io\n",
    "import sys\n",
    "import tqdm\n",
    "import yaml\n",
    "\n",
    "from addict import Dict\n",
    "from itertools import zip_longest\n",
    "from PIL import Image, ImageFilter\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from models.SegNet import SegNetBasic\n",
    "from dataset import PartAffordanceDataset, CenterCrop, ToTensor, Normalize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_normalize(x, mean=[0.2191, 0.2349, 0.3598], std=[0.1243, 0.1171, 0.0748]):\n",
    "    x[:, 0, :, :] = x[:, 0, :, :] * std[0] + mean[0]\n",
    "    x[:, 1, :, :] = x[:, 1, :, :] * std[1] + mean[1]\n",
    "    x[:, 2, :, :] = x[:, 2, :, :] * std[2] + mean[2]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign the colors to each class\n",
    "colors = torch.tensor([[0, 0, 0],         # class 0 'background'  black\n",
    "                       [255, 0, 0],       # class 1 'grasp'       red\n",
    "                       [255, 255, 0],     # class 2 'cut'         yellow\n",
    "                       [0, 255, 0],       # class 3 'scoop'       green\n",
    "                       [0, 255, 255],     # class 4 'contain'     sky blue\n",
    "                       [0, 0, 255],       # class 5 'pound'       blue\n",
    "                       [255, 0, 255],     # class 6 'support'     purple\n",
    "                       [255, 255, 255]    # class 7 'wrap grasp'  white\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class prediction to the mask\n",
    "def class_to_mask(cls):\n",
    "    \n",
    "    mask = colors[cls].transpose(1, 2).transpose(1, 3)\n",
    "    \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sample, device='cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    x, y0, y1 = sample['image'], sample['label'], sample['label1']\n",
    "    batch_len, _, H, W = x.shape\n",
    "        \n",
    "    task0 = torch.zeros((batch_len, 2, H, W))\n",
    "    task0[:, 0] = 1\n",
    "    task1 = torch.zeros((batch_len, 2, H, W))\n",
    "    task1[:, 1] = 1\n",
    "\n",
    "    x = x.to(device)\n",
    "    \n",
    "    task0 = task0.to(device)\n",
    "    task1 = task1.to(device)\n",
    "    \n",
    "    h0 = model(x, task0)\n",
    "    h1 = model(x, task1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        _, y0_pred = h0.max(1)\n",
    "        _, y1_pred = h1.max(1)\n",
    "    \n",
    "    true_mask0 = class_to_mask(y0)\n",
    "    pred_mask0 = class_to_mask(y0_pred)\n",
    "    true_mask1 = class_to_mask(y1)\n",
    "    pred_mask1 = class_to_mask(y1_pred)\n",
    "    \n",
    "    x = reverse_normalize(x)\n",
    "    \n",
    "    save_image(x, 'result/orig_image.jpg')\n",
    "    save_image(true_mask0, 'result/true_masks_task0.jpg')\n",
    "    save_image(pred_mask0, 'result/pred_masks_task0.jpg')\n",
    "    save_image(true_mask1, 'result/true_masks_task1.jpg')\n",
    "    save_image(pred_mask1, 'result/pred_masks_task1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegNetBasic(3, 2, 4)\n",
    "model.load_state_dict(torch.load('./result/best_mean_iou_model.prm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Dict(yaml.safe_load(open('./result/config.yaml')))\n",
    "\n",
    "\n",
    "\"\"\" DataLoader \"\"\"\n",
    "test_data = PartAffordanceDataset(CONFIG.test_data,\n",
    "                                config=CONFIG,\n",
    "                                transform=transforms.Compose([\n",
    "                                    CenterCrop(CONFIG),\n",
    "                                    ToTensor(),\n",
    "                                    Normalize()\n",
    "                                ]))\n",
    "\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in test_loader:\n",
    "    predict(model, sample)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
