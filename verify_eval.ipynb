{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import scipy.io\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "from addict import Dict\n",
    "from PIL import Image, ImageFilter\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from models.SegNet import SegNetBasic\n",
    "from models.discriminator import Discriminator\n",
    "from dataset import PartAffordanceDataset, PartAffordanceDatasetWithoutLabel\n",
    "from dataset import CenterCrop, ToTensor, Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SegNetBasic(3, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.weight, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegNetBasic(\n",
       "  (encoder1): Encoder(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encoder2): Encoder(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encoder3): Encoder(\n",
       "    (conv): Conv2d(80, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (encoder4): Encoder(\n",
       "    (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (conv): Conv2d(128, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder2): Decoder(\n",
       "    (conv): Conv2d(96, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder3): Decoder(\n",
       "    (conv): Conv2d(80, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (decoder4): Decoder(\n",
       "    (conv): Conv2d(64, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_train(model, sample, criterion_ce_full, optimizer, device):\n",
    "\n",
    "    ''' full supervised learning for segmentation network'''\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    x, y = sample['image'], sample['class']\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    h = model(x)     # shape => (N, 8, H, W)\n",
    "\n",
    "    loss_ce = criterion_ce_full(h, y)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss_ce.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_ce.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, device='cpu'):\n",
    "    model.eval()\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    intersection = torch.zeros(8)   # the dataset has 8 classes including background\n",
    "    union = torch.zeros(8)\n",
    "    \n",
    "    for k, sample in enumerate(test_loader):\n",
    "        x, y = sample['image'], sample['class']\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ypred = model(x)    # ypred.shape => (N, 8, H, W)\n",
    "            _, ypred = ypred.max(1)    # y_pred.shape => (N, 256, 320)\n",
    "\n",
    "        for i in range(8):\n",
    "            y_i = (y == i)           \n",
    "            ypred_i = (ypred == i)   \n",
    "            \n",
    "            inter = (y_i.byte() & ypred_i.byte()).float().sum().to('cpu')\n",
    "            intersection[i] += inter\n",
    "            union[i] += (y_i.float().sum() + ypred_i.float().sum()).to('cpu') - inter\n",
    "            \n",
    "        if k == 10:\n",
    "            break\n",
    "    \n",
    "        \n",
    "    \"\"\" iou[i] is the IoU of class i \"\"\"\n",
    "    iou = intersection / union\n",
    "    \n",
    "    taken_time = start - time.time()\n",
    "    \n",
    "    print(taken_time)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = Dict(yaml.safe_load(open('./result_segnet/config_segnet.yaml')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_with_label = PartAffordanceDataset('train.csv',\n",
    "                                        transform=transforms.Compose([\n",
    "                                            CenterCrop(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize()\n",
    "                                        ]))\n",
    "\n",
    "train_data_without_label = PartAffordanceDatasetWithoutLabel('train_without_label_4to1.csv',\n",
    "                                        transform=transforms.Compose([\n",
    "                                            CenterCrop(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize()\n",
    "                                        ]))\n",
    "\n",
    "test_data = PartAffordanceDataset('test.csv',\n",
    "                            transform=transforms.Compose([\n",
    "                                CenterCrop(),\n",
    "                                ToTensor(),\n",
    "                                Normalize()\n",
    "                            ]))\n",
    "\n",
    "train_loader_with_label = DataLoader(train_data_with_label, batch_size=CONFIG.batch_size, shuffle=True, num_workers=CONFIG.num_workers)\n",
    "train_loader_without_label = DataLoader(train_data_without_label, batch_size=CONFIG.batch_size, shuffle=True, num_workers=CONFIG.num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=CONFIG.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-57.366888999938965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8753,    nan,    nan,    nan, 0.0000,    nan,    nan,    nan])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(label, n_classes, device):\n",
    "    one_hot_label = torch.eye(n_classes, requires_grad=True, device=device)[label].transpose(1, 3).transpose(2, 3)\n",
    "    return one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, test_loader, device='cpu'):\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    intersections = torch.zeros(8).to(device)\n",
    "    unions = torch.zeros(8).to(device)\n",
    "    \n",
    "    for i, sample in enumerate(test_loader):\n",
    "        x = sample['image']\n",
    "        y = sample['class']\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            ypred = model(x)    # ypred.shape => (N, 8, H, W)\n",
    "            _, ypred = ypred.max(1)    # y_pred.shape => (N, 256, 320)\n",
    "\n",
    "        p = one_hot(ypred, 8, device).long()\n",
    "        t = one_hot(y, 8, device).long()\n",
    "        \n",
    "        intersection = torch.sum(p & t, (0,2,3))\n",
    "        union = torch.sum(p | t, (0, 2, 3))\n",
    "        \n",
    "        intersections += intersection.float()\n",
    "        unions += union.float()\n",
    "        \n",
    "        if i == 10:\n",
    "            break\n",
    "        \n",
    "    iou = intersections / unions\n",
    "    \n",
    "    taken_time = time.time() - start\n",
    "    print(taken_time)\n",
    "    \n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.96979212760925\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.8753,    nan,    nan,    nan, 0.0000,    nan,    nan,    nan])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(10, 8, 256, 320).long()\n",
    "b = torch.ones(10, 8, 256, 320).long()\n",
    "c = torch.zeros(10, 8, 256, 320).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "z =a | c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 8])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(z, (2,3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
