{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import sys\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image, ImageFilter\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "from models.deeplabv2 import DeepLabV2\n",
    "from models.msc import MSC\n",
    "from models.discriminator import Discriminator\n",
    "from dataset import PartAffordanceDataset, PartAffordanceDatasetWithoutLabel\n",
    "from dataset import CenterCrop, ToTensor, Normalize\n",
    "\n",
    "\n",
    "\n",
    "''' one-hot representation '''\n",
    "\n",
    "def one_hot(label, n_classes, device):\n",
    "    one_hot_label = torch.eye(n_classes, requires_grad=True, device=device)[label].transpose(1, 3).transpose(2, 3)\n",
    "    return one_hot_label\n",
    "    \n",
    "\n",
    "''' scheduler for learning rate '''\n",
    "\n",
    "def poly_lr_scheduler(optimizer, init_lr, iter, lr_decay_iter, max_iter, power):\n",
    "    if iter % lr_decay_iter or iter > max_iter:\n",
    "        return None\n",
    "    new_lr = init_lr * (1 - float(iter) / max_iter) ** power\n",
    "    optimizer.param_groups[0][\"lr\"] = new_lr\n",
    "    optimizer.param_groups[1][\"lr\"] = 10 * new_lr\n",
    "    optimizer.param_groups[2][\"lr\"] = 20 * new_lr\n",
    "\n",
    "\n",
    "def poly_lr_scheduler_d(optimizer, init_lr, iter, lr_decay_iter, max_iter, power):\n",
    "    if iter % lr_decay_iter or iter > max_iter:\n",
    "        return None\n",
    "    new_lr = init_lr * (1 - float(iter) / max_iter) ** power\n",
    "    optimizer.param_groups[0][\"lr\"] = new_lr\n",
    "    if len(optimizer.param_groups) > 1:\n",
    "        optimizer.param_groups[1]['lr'] = 10 * new_lr\n",
    "\n",
    "\n",
    "''' model, weight initialization, get params '''\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "\n",
    "\n",
    "def DeepLabV2_ResNet101_MSC(n_classes):\n",
    "    return MSC(\n",
    "        scale=DeepLabV2(\n",
    "            n_classes=n_classes, n_blocks=[3, 4, 23, 3], pyramids=[6, 12, 18, 24]\n",
    "        ),\n",
    "        pyramids=[0.5, 0.75],\n",
    "    )\n",
    "\n",
    "\n",
    "def get_params(model, key):\n",
    "    # For Dilated FCN\n",
    "    if key == \"1x\":\n",
    "        for m in model.named_modules():\n",
    "            if \"layer\" in m[0]:\n",
    "                if isinstance(m[1], nn.Conv2d):\n",
    "                    for p in m[1].parameters():\n",
    "                        yield p\n",
    "    # For conv weight in the ASPP module\n",
    "    if key == \"10x\":\n",
    "        for m in model.named_modules():\n",
    "            if \"aspp\" in m[0]:\n",
    "                if isinstance(m[1], nn.Conv2d):\n",
    "                    yield m[1].weight\n",
    "    # For conv bias in the ASPP module\n",
    "    if key == \"20x\":\n",
    "        for m in model.named_modules():\n",
    "            if \"aspp\" in m[0]:\n",
    "                if isinstance(m[1], nn.Conv2d):\n",
    "                    yield m[1].bias\n",
    "\n",
    "\n",
    "\n",
    "''' training '''\n",
    "\n",
    "def full_train(\n",
    "        model, model_d, sample, criterion_ce_full, criterion_bce, \n",
    "        optimizer, optimizer_d, ones, zeros, device):\n",
    "\n",
    "    ''' full supervised learning '''\n",
    "    \n",
    "    model.train()\n",
    "    model.scale.freeze_bn()\n",
    "    model_d.train()\n",
    "\n",
    "    # train segmentation network\n",
    "    x, y = sample['image'], sample['class']\n",
    "\n",
    "    batch_len = len(x)\n",
    "\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "\n",
    "    h = model(x)     # shape => (N, 8, H/8, W/8)\n",
    "    h = F.interpolate(h, size=(256, 256), mode='bilinear', align_corners=True)\n",
    "\n",
    "    h_ = h.detach()    # h_ is for calculating loss for discriminator\n",
    "    y_ = y.detach()    # y_is for the same purpose.  shape => (N, H, W)\n",
    "\n",
    "    d_out = model_d(h)    # shape => (N, 1, H/32, W/32)\n",
    "    d_out = F.interpolate(d_out, size=(256, 256), mode='bilinear', align_corners=True)    # shape => (N, 1, H, W)\n",
    "    d_out = d_out.squeeze()\n",
    "    \n",
    "    loss_ce = criterion_ce_full(h, y)\n",
    "    loss_adv = criterion_bce(d_out, ones[:batch_len])\n",
    "    loss_full = loss_ce + 0.01 * loss_adv\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_d.zero_grad()\n",
    "    loss_full.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    # train discriminator\n",
    "    seg_out = model_d(h_)    # shape => (N, 1, H/32, W/32)\n",
    "    seg_out = F.interpolate(seg_out, size=(256, 256), mode='bilinear', align_corners=True)    # shape => (N, 1, H, W)\n",
    "    seg_out = seg_out.squeeze()\n",
    "    \n",
    "    y_ = one_hot(y_, 8, device)    # shape => (N, 8, H, W)\n",
    "    true_out = model_d(y_)    # shape => (N, 1, H/32, W/32)\n",
    "    true_out = F.interpolate(true_out, size=(256, 256), mode='bilinear', align_corners=True)    # shape => (N, 1, H, W)\n",
    "    true_out = true_out.squeeze()\n",
    "\n",
    "    loss_d_fake = criterion_bce(seg_out, zeros[:batch_len])\n",
    "    loss_d_real = criterion_bce(true_out, ones[:batch_len])\n",
    "    loss_d = loss_d_fake + loss_d_real\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_d.zero_grad()\n",
    "    loss_d.backward()\n",
    "    optimizer_d.step()\n",
    "    \n",
    "    return loss_full.item(), loss_d.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def semi_train(\n",
    "        model, model_d, sample, criterion_ce_semi, criterion_bce, \n",
    "        optimizer, optimizer_d, ones, zeros, device):\n",
    "\n",
    "    ''' semi supervised learning '''\n",
    "    \n",
    "    model.train()\n",
    "    model.scale.freeze_bn()\n",
    "    model_d.eval()\n",
    "\n",
    "    # train segmentation network\n",
    "    x = sample['image']\n",
    "    batch_len = len(x)\n",
    "    \n",
    "    x = x.to(device)\n",
    "    \n",
    "    h = model(x)     # shape => (N, 8, H/8, W/8)\n",
    "    h = F.interpolate(h, size=(256, 256), mode='bilinear', align_corners=True)\n",
    "\n",
    "    _, h_ = torch.max(h, dim=1)    # to calculate the crossentropy loss. shape => (N, H, W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        d_out = model_d(h)    # shape => (N, 1, H/32, W/32)\n",
    "        d_out = F.interpolate(d_out, size=(256, 256), mode='bilinear', align_corners=True)    # shape => (N, 1, H, W)\n",
    "        d_out = d_out.squeeze()\n",
    "\n",
    "    loss_adv = criterion_bce(d_out, ones[:batch_len])\n",
    "\n",
    "\n",
    "    # if the pixel value of the output from discriminator is more than a threshold,\n",
    "    # its value is viewd as one from true label. Else, its value is ignored(value=255).\n",
    "    h_[d_out < 0.2] = 255\n",
    "\n",
    "    loss_ce = criterion_ce_semi(h, h_)\n",
    "    loss_semi = 0.001 * loss_adv + 0.1 * loss_ce\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    optimizer_d.zero_grad()\n",
    "    loss_semi.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss_semi.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = './models/deeplabv2_resnet101_COCO_init.pth'\n",
    "class_weight_flag = True\n",
    "batch_size = 6\n",
    "num_workers = 4\n",
    "max_epoch = 1000\n",
    "learning_rate = 0.00025\n",
    "learning_rate_d = 0.0001\n",
    "n_classes = 8\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' DataLoader '''\n",
    "train_data_with_label = PartAffordanceDataset('train_with_label.csv',\n",
    "                                        transform=transforms.Compose([\n",
    "                                            CenterCrop(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize()\n",
    "                                        ]))\n",
    "\n",
    "train_data_without_label = PartAffordanceDatasetWithoutLabel('train_without_label.csv',\n",
    "                                        transform=transforms.Compose([\n",
    "                                            CenterCrop(),\n",
    "                                            ToTensor(),\n",
    "                                            Normalize()\n",
    "                                         ]))\n",
    "\n",
    "test_data = PartAffordanceDataset('test.csv',\n",
    "                            transform=transforms.Compose([\n",
    "                                CenterCrop(),\n",
    "                                ToTensor(),\n",
    "                                Normalize()\n",
    "                            ]))\n",
    "\n",
    "train_loader_with_label = DataLoader(train_data_with_label, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "train_loader_without_label = DataLoader(train_data_without_label, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "''' define model, optimizer, loss '''\n",
    "model = DeepLabV2_ResNet101_MSC(n_classes)\n",
    "model_d = Discriminator(n_classes)\n",
    "\n",
    "model.apply(init_weights)\n",
    "model_d.apply(init_weights)\n",
    "\n",
    "state_dict = torch.load(pretrained_model)\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "model.to(device)\n",
    "model_d.to(device)\n",
    "\n",
    "optimizer = optim.SGD(\n",
    "                    params=[{\n",
    "                        \"params\": get_params(model, key=\"1x\"),\n",
    "                        \"lr\": learning_rate,\n",
    "                        \"weight_decay\": 5.0e-4,\n",
    "                            },\n",
    "                            {\n",
    "                        \"params\": get_params(model, key=\"10x\"),\n",
    "                        \"lr\": 10 * learning_rate,\n",
    "                        \"weight_decay\": 5.0e-4,\n",
    "                            },\n",
    "                            {\n",
    "                            \"params\": get_params(model, key=\"20x\"),\n",
    "                            \"lr\": 20 * learning_rate,\n",
    "                            \"weight_decay\": 0.0,\n",
    "                            }],\n",
    "                    momentum=0.9)\n",
    "\n",
    "\n",
    "\n",
    "optimizer_d = optim.Adam(model_d.parameters(), lr=learning_rate_d, betas=(0.9,0.99))\n",
    "\n",
    "if class_weight_flag:\n",
    "    class_weight = torch.tensor([0.0057, 0.4689, 1.0000, 1.2993, \n",
    "                                0.4240, 2.3702, 1.7317, 0.8149])    # refer to dataset.py\n",
    "    criterion_ce_full = nn.CrossEntropyLoss(weight=class_weight.to(device))\n",
    "else:\n",
    "    criterion_ce_full = nn.CrossEntropyLoss()\n",
    "\n",
    "criterion_ce_semi = nn.CrossEntropyLoss(ignore_index=255)\n",
    "criterion_bce = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# supplementary constant for discriminator\n",
    "ones = torch.ones(batch_size, 256, 256).to(device)\n",
    "zeros = torch.zeros(batch_size, 256, 256).to(device)\n",
    "\n",
    "\n",
    "''' training '''\n",
    "\n",
    "losses_full = []\n",
    "losses_semi = []\n",
    "losses_d = []\n",
    "val_iou = []\n",
    "mean_iou = []\n",
    "best_iou = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1967 [00:00<?, ?it/s]/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/nn/functional.py:1961: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8698792457580566 1.253151297569275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 1/1967 [00:01<41:05,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011708456091582775\n",
      "11.97008991241455 4.213683128356934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 2/1967 [00:02<40:32,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008660722523927689\n",
      "3.994086265563965 0.36702650785446167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 3/1967 [00:03<39:42,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007229161448776722\n",
      "4.498116970062256 0.3504098653793335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 4/1967 [00:04<39:15,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002384445397183299\n",
      "4.05718994140625 0.2752782702445984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 5/1967 [00:05<39:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13536643981933594\n",
      "3.9291133880615234 0.5638864040374756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 6/1967 [00:07<38:37,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004842708352953196\n",
      "4.964388370513916 0.20941978693008423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 7/1967 [00:08<38:35,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002662213984876871\n",
      "2.342280149459839 0.2223885953426361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 8/1967 [00:09<38:24,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10166565328836441\n",
      "3.393409013748169 3.2462804317474365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 9/1967 [00:10<38:08,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13631108403205872\n",
      "2.080451488494873 0.33272701501846313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 10/1967 [00:11<37:56,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0060912128537893295\n",
      "1.844444990158081 0.25567737221717834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 11/1967 [00:12<37:50,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006948020309209824\n",
      "2.46440052986145 0.32061752676963806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 12/1967 [00:14<37:45,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004863671492785215\n",
      "1.927861213684082 0.40020695328712463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 13/1967 [00:15<37:43,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0035459098871797323\n",
      "2.2502543926239014 0.44072863459587097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 14/1967 [00:16<37:38,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0036840436514467\n",
      "1.95070219039917 0.38630300760269165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 15/1967 [00:17<37:36,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005218432750552893\n",
      "2.022118091583252 0.3907071053981781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 16/1967 [00:18<37:34,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005122071132063866\n",
      "1.9362027645111084 0.3504157066345215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 17/1967 [00:19<37:31,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005259358324110508\n",
      "2.290332078933716 0.35551223158836365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 18/1967 [00:20<37:29,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008057921193540096\n",
      "2.0660722255706787 0.299469918012619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 19/1967 [00:22<37:27,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010536549612879753\n",
      "2.083909034729004 0.2644241154193878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 20/1967 [00:23<37:30,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05754852294921875\n",
      "2.344194173812866 0.3417905271053314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 21/1967 [00:24<37:27,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.049362048506736755\n",
      "2.3307483196258545 0.26051437854766846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 22/1967 [00:25<37:25,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07296470552682877\n",
      "2.13665509223938 0.6764751672744751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 23/1967 [00:26<37:24,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07109033316373825\n",
      "1.785438060760498 0.5833394527435303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|          | 24/1967 [00:27<37:24,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07179375737905502\n",
      "1.8190076351165771 1.0444958209991455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 25/1967 [00:29<38:02,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06407677382230759\n",
      "2.15037202835083 1.5430760383605957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 26/1967 [00:30<38:13,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.051441941410303116\n",
      "2.0724167823791504 1.6285820007324219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 27/1967 [00:31<38:30,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04607565701007843\n",
      "2.01420521736145 1.1314961910247803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 28/1967 [00:32<38:43,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04255591705441475\n",
      "1.751344084739685 0.39074862003326416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▏         | 29/1967 [00:33<38:48,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00858160387724638\n",
      "2.3360936641693115 0.4577636122703552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 30/1967 [00:35<38:44,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009269634261727333\n",
      "1.8112484216690063 0.8698969483375549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 31/1967 [00:36<38:50,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007887675426900387\n",
      "2.150132179260254 1.0758354663848877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 32/1967 [00:37<38:51,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006908936891704798\n",
      "1.8819122314453125 0.8515539169311523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 33/1967 [00:38<38:58,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006734306458383799\n",
      "2.0483977794647217 0.7720101475715637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 34/1967 [00:39<38:43,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006717617157846689\n",
      "1.8270946741104126 0.5364201068878174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 35/1967 [00:41<38:16,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006812836974859238\n",
      "1.832937479019165 0.321870356798172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 36/1967 [00:42<38:18,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007502488326281309\n",
      "2.067319631576538 0.2914794981479645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 37/1967 [00:43<38:15,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007698163390159607\n",
      "2.0559587478637695 0.23794183135032654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 38/1967 [00:44<38:14,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006840172223746777\n",
      "1.8440251350402832 0.18941205739974976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 39/1967 [00:45<38:19,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005976554471999407\n",
      "2.3094379901885986 0.1665370911359787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 40/1967 [00:47<38:09,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00518804183229804\n",
      "1.9418361186981201 0.2282865345478058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 41/1967 [00:48<37:45,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.034713950008153915\n",
      "1.9351756572723389 0.20811393857002258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 42/1967 [00:49<37:36,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03173390030860901\n",
      "1.7852531671524048 0.25071749091148376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 43/1967 [00:50<37:27,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.046767182648181915\n",
      "2.0552620887756348 0.3405505120754242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 44/1967 [00:51<37:37,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05214646831154823\n",
      "2.281172275543213 0.4594035744667053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 45/1967 [00:52<37:23,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0578266978263855\n",
      "1.9729678630828857 0.5519734621047974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 46/1967 [00:54<37:14,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0654635950922966\n",
      "2.091203212738037 0.4291480779647827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 47/1967 [00:55<37:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0841076597571373\n",
      "1.9007800817489624 0.21572357416152954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 48/1967 [00:56<37:04,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10133564472198486\n",
      "2.332698106765747 0.13438966870307922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 49/1967 [00:57<37:02,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10387008637189865\n",
      "1.9274110794067383 0.25297993421554565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 50/1967 [00:58<36:59,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09944798052310944\n",
      "1.7868869304656982 0.1923980712890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 51/1967 [00:59<36:57,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10541000962257385\n",
      "1.8932772874832153 0.2853808104991913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 52/1967 [01:01<36:53,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09207338094711304\n",
      "1.9082915782928467 0.20880092680454254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 53/1967 [01:02<36:50,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006519518326967955\n",
      "1.6963984966278076 0.23023900389671326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 54/1967 [01:03<36:50,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006707970984280109\n",
      "1.9847044944763184 0.28108543157577515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 55/1967 [01:04<36:48,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.024528127163648605\n",
      "2.0366339683532715 0.3741839528083801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 56/1967 [01:05<36:47,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029199114069342613\n",
      "1.8934401273727417 0.31763288378715515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 57/1967 [01:06<36:46,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.036558378487825394\n",
      "2.183948040008545 0.45450419187545776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 58/1967 [01:07<36:43,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04945949465036392\n",
      "2.111417293548584 0.42479872703552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 59/1967 [01:09<36:43,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.056809909641742706\n",
      "1.8871766328811646 0.3573371171951294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 60/1967 [01:10<36:44,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0515313595533371\n",
      "1.9374065399169922 0.37023860216140747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 61/1967 [01:11<36:41,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03955599665641785\n",
      "1.9340322017669678 0.4208599925041199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 62/1967 [01:12<36:41,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03100588172674179\n",
      "1.977989912033081 0.5030295848846436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 63/1967 [01:13<36:38,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02473408728837967\n",
      "1.8147164583206177 0.4861946702003479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 64/1967 [01:14<36:34,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01704687997698784\n",
      "1.8672401905059814 0.3234764337539673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 65/1967 [01:16<36:34,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014907840639352798\n",
      "2.051997661590576 0.3503275513648987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 66/1967 [01:17<36:33,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007723917253315449\n",
      "2.049039602279663 0.40981659293174744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 67/1967 [01:18<36:32,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007902977056801319\n",
      "2.0364768505096436 0.3540683090686798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 68/1967 [01:19<36:30,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007337816525250673\n",
      "1.9757226705551147 0.2874699831008911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 69/1967 [01:20<36:31,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08282433450222015\n",
      "1.797174096107483 0.24017083644866943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 70/1967 [01:21<36:31,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08863652497529984\n",
      "1.9535452127456665 0.32859477400779724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 71/1967 [01:22<36:27,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07653693109750748\n",
      "1.5670963525772095 0.2532805800437927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 72/1967 [01:24<36:48,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05998126417398453\n",
      "1.6313265562057495 0.31231892108917236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 73/1967 [01:25<37:11,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.028836306184530258\n",
      "1.3697766065597534 0.612615704536438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 74/1967 [01:26<37:28,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01534265000373125\n",
      "2.0430400371551514 0.7894971966743469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 75/1967 [01:27<37:42,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011391492560505867\n",
      "2.7277204990386963 0.5070832371711731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 76/1967 [01:28<37:51,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011684981174767017\n",
      "1.4180712699890137 0.5150801539421082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 77/1967 [01:30<37:44,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011525508016347885\n",
      "2.0453577041625977 0.6577736735343933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 78/1967 [01:31<37:25,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009751927107572556\n",
      "1.5689260959625244 0.5549251437187195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 79/1967 [01:32<37:04,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007900122553110123\n",
      "2.2243895530700684 0.6844226717948914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 80/1967 [01:33<37:01,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0062259407714009285\n",
      "1.8258659839630127 0.42357996106147766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 81/1967 [01:34<36:50,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004781669471412897\n",
      "1.7842903137207031 0.3134675920009613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 82/1967 [01:36<36:55,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12046321481466293\n",
      "1.9656651020050049 0.2698366045951843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 83/1967 [01:37<36:40,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09806180000305176\n",
      "2.0694022178649902 0.3041979670524597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 84/1967 [01:38<36:31,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07933719456195831\n",
      "1.9231666326522827 0.19583441317081451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 85/1967 [01:39<36:26,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.058030735701322556\n",
      "2.330043315887451 0.34594419598579407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 86/1967 [01:40<36:20,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05012979358434677\n",
      "2.07830810546875 0.43461453914642334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 87/1967 [01:41<36:22,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05211004242300987\n",
      "1.980574131011963 0.48374998569488525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▍         | 88/1967 [01:42<36:15,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05370006710290909\n",
      "1.7598956823349 0.39124464988708496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 89/1967 [01:44<36:12,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04902023449540138\n",
      "1.710841178894043 0.3675198554992676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 90/1967 [01:45<36:09,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.029899023473262787\n",
      "1.697337031364441 0.2514742910861969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 91/1967 [01:46<36:07,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02063891291618347\n",
      "1.633617877960205 0.20001038908958435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 92/1967 [01:47<36:02,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02492283098399639\n",
      "2.125988006591797 0.28692153096199036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 93/1967 [01:48<36:14,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.021364454180002213\n",
      "1.913976788520813 0.30659234523773193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 94/1967 [01:49<36:44,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0061536431312561035\n",
      "1.5616105794906616 0.32357311248779297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 95/1967 [01:51<37:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006108004134148359\n",
      "1.4487308263778687 0.32076650857925415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 96/1967 [01:52<37:15,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005899030715227127\n",
      "1.851867914199829 0.42920202016830444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 97/1967 [01:53<37:02,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.005165720358490944\n",
      "2.192650556564331 0.5112618803977966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 98/1967 [01:54<36:51,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004282210487872362\n",
      "1.8800337314605713 0.4106219410896301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▌         | 99/1967 [01:55<36:33,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027784625068306923\n",
      "2.2203335762023926 0.39545154571533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 100/1967 [01:57<36:24,  1.17s/it]Process Process-1:\n",
      "Process Process-2:\n",
      "Process Process-5:\n",
      "Process Process-4:\n",
      "Process Process-8:\n",
      "Process Process-7:\n",
      "Process Process-3:\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "KeyboardInterrupt\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/yuchi/anaconda3/envs/torch/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050244495272636414\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-41509aa79015>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             loss_full, loss_d = full_train(\n\u001b[1;32m     49\u001b[0m                                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_ce_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion_bce\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                                     optimizer, optimizer_d, ones, zeros, device)\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_full\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-9e8a6c46d03a>\u001b[0m in \u001b[0;36mfull_train\u001b[0;34m(model, model_d, sample, criterion_ce_full, criterion_bce, optimizer, optimizer_d, ones, zeros, device)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mloss_ce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_ce_full\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     \u001b[0mloss_adv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion_bce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0mloss_full\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_ce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_adv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.5/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.5/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    571\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.5/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   1660\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1661\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'elementwise_mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1662\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1663\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1664\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "\n",
    "    epoch_loss_full = 0.0\n",
    "    epoch_loss_d = 0.0\n",
    "    epoch_loss_semi = 0.0\n",
    "\n",
    "    poly_lr_scheduler(\n",
    "        optimizer=optimizer,\n",
    "        init_lr=learning_rate,\n",
    "        iter=epoch - 1,\n",
    "        lr_decay_iter=10,\n",
    "        max_iter=max_epoch,\n",
    "        power=0.9,\n",
    "    )\n",
    "\n",
    "    poly_lr_scheduler_d(\n",
    "        optimizer=optimizer_d,\n",
    "        init_lr=learning_rate_d,\n",
    "        iter=epoch - 1,\n",
    "        lr_decay_iter=10,\n",
    "        max_iter=max_epoch,\n",
    "        power=0.9,\n",
    "    )\n",
    "\n",
    "\n",
    "    # only supervised learning\n",
    "    if epoch < 0:\n",
    "        for i, sample in tqdm.tqdm(enumerate(train_loader_with_label), \n",
    "                                   total=len(train_loader_with_label)):\n",
    "\n",
    "            loss_full, loss_d = full_train(\n",
    "                                    model, model_d, sample, criterion_ce_full, criterion_bce,\n",
    "                                    optimizer, optimizer_d, ones, zeros, device)\n",
    "            print(loss_full, loss_d)\n",
    "            epoch_loss_full += loss_full\n",
    "            epoch_loss_d += loss_d\n",
    "\n",
    "        losses_full.append(epoch_loss_full / i)   # mean loss over all samples\n",
    "        losses_d.append(epoch_loss_d / i)\n",
    "        losses_semi.append(0.0)\n",
    "\n",
    "\n",
    "    # semi-supervised learning\n",
    "    if epoch >= 0:\n",
    "        for i, (sample1, sample2) in tqdm.tqdm(enumerate(zip(train_loader_with_label, train_loader_without_label)), \n",
    "                                                total=len(train_loader_with_label)):\n",
    "\n",
    "            loss_full, loss_d = full_train(\n",
    "                                    model, model_d, sample1, criterion_ce_full, criterion_bce,\n",
    "                                    optimizer, optimizer_d, ones, zeros, device)\n",
    "            \n",
    "            epoch_loss_full += loss_full\n",
    "            epoch_loss_d += loss_d\n",
    "\n",
    "            loss_semi = semi_train(\n",
    "                                    model, model_d, sample2, criterion_ce_semi, criterion_bce,\n",
    "                                    optimizer, optimizer_d, ones, zeros, device)\n",
    "            \n",
    "            epoch_loss_semi += loss_semi\n",
    "\n",
    "        losses_full.append(epoch_loss_full / i)   # mean loss over all samples\n",
    "        losses_d.append(epoch_loss_d / i)\n",
    "        losses_semi.append(epoch_loss_semi / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
